{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67e116b",
   "metadata": {},
   "source": [
    "# Spatial and temporal resampling of gridded ECMWF data onto a satellite's swath\n",
    "\n",
    "For the retrieval of physical paramters in the atmosphere via Optimal Estimation we need apriori knowlegdge of the quantity we want to retrieve; this apriori knowledge can be obtained from a forecast model. \n",
    "\n",
    "ECMWF's forecasts are available in different spatial and temporal resolutions, in particular in this notebook we work with a *0.25/0.25* regular *lon/lat* grid in **space** and 16 steps for 2 analysis times per day, time/step combination gives **temporal** coverage of data every hour: \n",
    "*time* is the reference time where the analysis is performed and observations are used to update the model, whereas *step* is related to the time steps that contain the temporal evolution of the forecast model.\n",
    "\n",
    "Once the ECMWF's data is available with a given spatial/temporal resolution, we focus on the satellite observations, to be specific \"where\" are these observations located (i.e. what longitude and latitude); because the satellite does not care much about grids, we rely on it's swath definition: how the instrument *samples* in space and time.\n",
    "\n",
    "Different instruments (and data providers) might have different versions of how to refer to the swath (however the concept of swath is happily enough, unique); in our case we use CMSAF [data](https://wui.cmsaf.eu/safira/action/viewDoiDetails?acronym=FCDR_MWI_V003) (i.e. Brightness Temperatures). \n",
    "Each specific sample (observation) is located at a specific longitude and latitude combination, so our goal is: to interpolate the ECMWF's variable (which is defined on the regular *lon/lat* grid) onto the specific locations in our satellite's swath. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd505ab",
   "metadata": {},
   "source": [
    "In this notebook we use [Pyresample](https://pyresample.readthedocs.io/en/latest/)'s functionality to efficiently resample data from a regular grid onto a swath. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c342a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import cf_xarray as cfxr\n",
    "import xesmf as xe\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import pyproj\n",
    "import pyresample\n",
    "from pyresample import create_area_def, load_area, data_reduce, utils, AreaDefinition\n",
    "from pyresample.geometry import SwathDefinition, GridDefinition\n",
    "from pyresample.kd_tree import resample_nearest, resample_gauss \n",
    "from pyresample.bilinear import XArrayBilinearResampler #NumpyBilinearResampler #\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e889a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append('/home/mario/Documents/Coursera\\\n",
    "#/Unsupervised/week1/Labs/Lab2/Files/home/jovyan/work')\n",
    "#from utils import *\n",
    "print(pyresample.__version__)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebbc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MALLOC_TRIM_THRESHOLD_\"] = \"0\"#\"65536\"\n",
    "\n",
    "from dask.distributed import Client, progress, LocalCluster\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde466cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satellite data:\n",
    "#dataSatDir = '/home/mario/Data/CMSAF/ssims/F16/'\n",
    "dataSatDir = '/home/mario/Data/CMSAF/ssims/F16/ORD47662/'\n",
    "#dataSatDir = '/nobackup/users/echeverr/data/cmsaf/ssmis/F16/'\n",
    "fileSatID = 'BTRin20140909000000324SSF1601GL.nc'\n",
    "\n",
    "# ECMWF data:\n",
    "#dataECMWFDir ='/home/mario/Data/Covariance_means/MARS_api_data/datasetsApriori/'\n",
    "#dataECMWFDir = '/nobackup/users/echeverr/data/ECMWF_era5/MARS_api_data/datasetsApriori/'\n",
    "dataECMWFDir ='/home/mario/Data/Covariance_means/MARS_api_data/datasetsAprioriRegGrid/'\n",
    "\n",
    "#Test only:\n",
    "\n",
    "auxDataECMWFDir = '/home/mario/Data/Covariance_means/MARS_api_data/ERA5_data/datasets/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_info = xr.open_mfdataset(dataECMWFDir+'profiles*.grib', \n",
    "                                 engine=\"cfgrib\") #, chunks={'time': 50, 'latitude': 50, 'longitude': 200})\n",
    "surface_info = xr.open_mfdataset(dataECMWFDir+'surface*.grib', \n",
    "                                 engine=\"cfgrib\") #, chunks={'time': 50,'latitude': 50, 'longitude': 200})\n",
    "\n",
    "\n",
    "work_ds = profile_info.merge(surface_info).copy()\n",
    "\n",
    "work_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e5453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is only auxiliary: I used \"cdo\" to convert the reduced Gaussian \n",
    "# grid datasets (N320) into a regular 0.25x0.25 deg**2 grid (ECMWF MARS was not\n",
    "# available at the time of this test, so I could not download the dataset in \n",
    "# the regular grid).\n",
    "# The interpolation uses a bilinear interpolation (cdo documentation); but the\n",
    "# resulting grid (lon, lat) has slight differences respect to the ECMWF regular grid\n",
    "\n",
    "# In this block I just take the (lon,lat) from another 0.25x0.25 deg**2 ECMWF\n",
    "# dataset and replace my cdo regular grid with it for consistency.\n",
    "\n",
    "aux_info = xr.open_mfdataset(auxDataECMWFDir+'surface*.grib', \n",
    "                                 engine=\"cfgrib\")\n",
    "work_ds['latitude'] = aux_info['latitude'][::-1] # The order in cdo is different\n",
    "work_ds['longitude'] = aux_info['longitude']\n",
    "work_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c206e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0070a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#work_ECMWF_ds = work_ds.isel(time=slice(0,2),step=0)\n",
    "#work_ECMWF_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0500b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create dataset (ECMWF) indexing the right time-step combinations.\n",
    "# We use stack to have a single reference time at the end:\n",
    "ECMWF_ds = work_ds.isel(step=slice(0,12)).stack(time2=(\"time\",\"step\"))\n",
    "\n",
    "# After stacking time/step the new multi-index variable is not very useful\n",
    "# as a time reference; we then create the new time dimension as the sum\n",
    "# of the analysis time and the step (so time + step):\n",
    "ECMWF_ds['time2'] = (work_ds.isel(step=slice(0,12)).time + \n",
    " work_ds.isel(step=slice(0,12)).step).stack(time2=(\"time\",\"step\"))\n",
    "#ECMWF_ds['longitude'].values = ECMWF_ds.longitude.values - 180.0    # Reset lon to [-180,180]\n",
    "ECMWF_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c88aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open satellite dataset at highest level (just to get the channels information):\n",
    "\n",
    "#ds = xr.open_dataset(dataSatDir+fileID)\n",
    "ds = xr.open_mfdataset(dataSatDir+'*.nc')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b88e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open specific scenes containing the satellite observations:\n",
    "\n",
    "scenes_list = ['scene_env1', 'scene_env2']\n",
    "scene_BT = []\n",
    "\n",
    "for scene in scenes_list:        \n",
    "    scene_BT.append(xr.open_mfdataset(\n",
    "        dataSatDir+'*.nc', combine = 'nested', \n",
    "        concat_dim='time', group = scene)) \n",
    "\n",
    "#for scene in scenes_list:\n",
    "    #scene_BT.append(xr.open_dataset(dataSatDir+fileID, group = scene))\n",
    "    #scene_BT.append(xr.open_mfdataset(dataSatDir+'*.nc', group = scene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_BT[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_BT = xr.concat(scene_BT, dim = 'scene_channel').drop_vars([\n",
    "])\n",
    "\n",
    "ds_BT['lat'] = ds_BT.lat[0,:,:]\n",
    "ds_BT['lon'] = ds_BT.lon[0,:,:]\n",
    "ds_BT['eia'] = ds_BT.eia[0,:,:]\n",
    "ds_BT['sft'] = ds_BT.sft[0,:,:]\n",
    "ds_BT['qc_fov'] = ds_BT.qc_fov[0,:,:]\n",
    "ds_BT['laz'] = ds_BT.laz[0,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3dee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_aux = ds_BT.assign_coords(time=ds.time).sel(\n",
    "    scene_channel=[11,12,14,15]).where(ds_BT.sft==0)\n",
    "\n",
    "ds_aux['central_freq'] = ds['central_freq'][0,0,ds_aux['scene_channel']]\n",
    "\n",
    "\n",
    "# Create working satellite dataset:\n",
    "\n",
    "SAT_ds = ds_aux #.drop_dims(drop_dims = ['date','channel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730eb6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined desired period of time to analyze:\n",
    "initSat_date = np.datetime64('2014-10-02T00:00:00.000') \n",
    "endSat_date = np.datetime64('2014-10-02T00:59:59.000')\n",
    "\n",
    "# Find best match (e.g. nearest) for the times present in the dataset:\n",
    "init_date = SAT_ds.time.sel(time=initSat_date, method = \"nearest\")\n",
    "end_date = SAT_ds.time.sel(time=endSat_date, method = \"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_SAT_ds = SAT_ds.sel(time=slice(init_date,end_date),\n",
    "                              #scene_channel = slice(11,15)\n",
    "                        )\n",
    "                             #.transpose(...,\"scene_channel\")\n",
    "work_SAT_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e55fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_2h = np.timedelta64(1, 'h') # Useful delta to create overlap in time\n",
    "\n",
    "# Initial and final times of the overlap between the two datasets (satellite and ECMWF).\n",
    "# We select as initial time the initial observation time \"minus\" 2 hours and\n",
    "# as final time the final observation time \"plus\" 2 hours\n",
    "timeOverlapInit = ECMWF_ds.time2.sel(\n",
    "    time2=work_SAT_ds.time.min() - delta_2h, method = \"nearest\")\n",
    "timeOverlapEnd = ECMWF_ds.time2.sel(\n",
    "    time2=work_SAT_ds.time.max() + delta_2h, method = \"nearest\")\n",
    "\n",
    "work_ECMWF_ds = ECMWF_ds.sel(time2 =  slice(timeOverlapInit,timeOverlapEnd)\n",
    "                            )\n",
    "\n",
    "# We reorder the dimensions with time2 as last dimension;\n",
    "# this because we want to exploit pyresample's ability\n",
    "# to resample multiple \"channels\" at the same time, as long\n",
    "# as the \"channels\" (or time instants in this setting)\n",
    "# are located in the last dimension:\n",
    "work_ECMWF_ds = work_ECMWF_ds.transpose(...,\n",
    "                                        'latitude','longitude','time2')\n",
    "work_ECMWF_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af157c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279eae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define swath using PyResample's SwathDefinition (geometry def.): \n",
    "SAT_swath_def = SwathDefinition(lons = work_SAT_ds.lon.values, \n",
    "                                lats = work_SAT_ds.lat.values)\n",
    "\n",
    "# Define grid using PyResample's GridDefiniton (geometry def.):\n",
    "lon2d,lat2d = np.meshgrid(work_ECMWF_ds.longitude, \n",
    "                          work_ECMWF_ds.latitude)\n",
    "ECMWF_grid_def = GridDefinition(lons=lon2d, lats=lat2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4284f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling using nearest neighbour:\n",
    "\n",
    "ECMWF_on_SAT = resample_nearest(ECMWF_grid_def, work_ECMWF_ds.u10n.values, \\\n",
    "        SAT_swath_def, radius_of_influence=30000, fill_value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0de8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling Gaussian:\n",
    "\n",
    "ECMWF_on_SAT_gauss = resample_gauss(ECMWF_grid_def, work_ECMWF_ds.u10n.values, \\\n",
    "               SAT_swath_def, radius_of_influence=30000, neighbours=10,\\\n",
    "               sigmas=30000*np.ones(len(work_ECMWF_ds.time2.values)), fill_value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64a5883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BilinearResampler for xarray objects does not support either\n",
    "# SwathDefinition or GridDefinition at present! (26 Sept. 2022)\n",
    "#resampler = XArrayBilinearResampler(ECMWF_grid_def, SAT_swath_def, 50e3)\n",
    "#result = resampler.resample(work_ECMWF_ds.u10n[0,:,:])\n",
    "#result\n",
    "\n",
    "#resampler = XArrayBilinearResampler(ECMWF_grid_def, SAT_swath_def, 50e3)\n",
    "#result = resampler.resample(work_ECMWF_ds.u10n[0,:,:])\n",
    "#result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save interpolated data: this evidently needs to improve!\n",
    "#work_SAT_ds['data']=work_SAT_ds.lat\n",
    "#work_SAT_ds['data'].data = ECMWF_on_SAT\n",
    "#work_SAT_ds['data']\n",
    "\n",
    "work_SAT_ds['u10n_apriori_nn'] = xr.DataArray(\n",
    "                data   = ECMWF_on_SAT,  # enter data here\n",
    "                dims   = ['time','scene_across_track','time4interpolation'],\n",
    "                coords = {'time': work_SAT_ds.time, \n",
    "                          'scene_across_track': work_SAT_ds.scene_across_track,\n",
    "                         'time4interpolation': work_ECMWF_ds.time2.values},\n",
    "                attrs  = {\n",
    "                    #'_FillValue': -999.9,\n",
    "                    'description': 'u10n from ECMWFs forecast resampled with\\\n",
    "                    PyResample (Nearest Neighbour resampler) to satellite swath',\n",
    "                    'units'     : 'm/s'\n",
    "                    }\n",
    "                ) #.chunk({\"time\": chunk_size_time,\n",
    "                  #       \"scene_across_track\": chunk_size_s_a_t})\n",
    "    \n",
    "work_SAT_ds['u10n_apriori_nn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65dacda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save interpolated data: this evidently needs to improve!\n",
    "#work_SAT_ds['dataGauss']=work_SAT_ds.lat\n",
    "#work_SAT_ds['dataGauss'].data = ECMWF_on_SAT_gauss\n",
    "#work_SAT_ds['dataGauss']\n",
    "\n",
    "work_SAT_ds['u10n_apriori_gauss'] = xr.DataArray(\n",
    "                data   = ECMWF_on_SAT_gauss,  # enter data here\n",
    "                dims   = ['time','scene_across_track','time4interpolation'],\n",
    "                coords = {'time': work_SAT_ds.time, \n",
    "                          'scene_across_track': work_SAT_ds.scene_across_track,\n",
    "                         'time4interpolation': work_ECMWF_ds.time2.values},\n",
    "                attrs  = {\n",
    "                    #'_FillValue': -999.9,\n",
    "                    'description': 'u10n from ECMWFs forecast resampled with\\\n",
    "                    PyResample (Nearest Neighbour resampler) to satellite swath',\n",
    "                    'units'     : 'm/s'\n",
    "                    }\n",
    "                ) #.chunk({\"time\": chunk_size_time,\n",
    "                  #       \"scene_across_track\": chunk_size_s_a_t})\n",
    "work_SAT_ds['u10n_apriori_gauss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bfd237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb843e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time interpolation:\n",
    "# We want to interpolate to the middle of the observation batch:\n",
    "time_interp = init_date + (end_date-init_date)/2 \n",
    "\n",
    "# Select the nearest valid time i.e. a time instant\n",
    "# that exists in the observations:\n",
    "time_interp = work_SAT_ds.time.sel(time=time_interp, method = \"nearest\")\n",
    "\n",
    "# Interpolate using xarray's (scipy under the hood) capabilities:\n",
    "# xarray.interp documentation: https://docs.xarray.dev/en/stable/user-guide/interpolation.html\n",
    "# Check xarray.interp documentation for explanation on the use of: \n",
    "# interpolate_na() and dropna()\n",
    "\n",
    "#work_SAT_ds['u10n_apriori_gauss_interp'] =\\\n",
    "#    work_SAT_ds.u10n_apriori_gauss.interpolate_na(\"time\").dropna(\"time\")\\\n",
    "#               .interp(time4interpolation=time_interp.values, method=\"cubic\")\n",
    "work_SAT_ds['u10n_apriori_gauss_interp'] =\\\n",
    "    work_SAT_ds.u10n_apriori_gauss.interp(time4interpolation=time_interp.values, method=\"linear\")\n",
    "\n",
    "work_SAT_ds['u10n_apriori_gauss_interp'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0278ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc773a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineArea(corners, proj_id, datum):\n",
    "    #corners=parseMeta(data_name)\n",
    "\n",
    "    lat_0 = '{lat_0:5.2f}'.format_map(corners)\n",
    "    lon_0= '{lon_0:5.2f}'.format_map(corners)\n",
    "    lon_bbox = [corners['min_lon'],corners['max_lon']]\n",
    "    lat_bbox = [corners['min_lat'],corners['max_lat']]\n",
    "    area_dict = dict(datum=datum,lat_0=lat_0,lon_0=lon_0,\n",
    "                proj=proj_id,units='m')\n",
    "\n",
    "    #area_dict = dict(datum=datum,lat_0=-15,lon_0=60,\n",
    "    #            proj=proj_id,units='m',a=6370997.0,)\n",
    "\n",
    "    prj=pyproj.Proj(area_dict)\n",
    "    x, y = prj(lon_bbox, lat_bbox)\n",
    "    xsize=200\n",
    "    ysize=200\n",
    "    area_id = 'granule'\n",
    "    area_name = 'modis swath 5min granule'\n",
    "    area_extent = (x[0], y[0], x[1], y[1])\n",
    "    print(area_extent)\n",
    "    area_def = AreaDefinition(area_id, area_name, proj_id, \n",
    "                                   area_dict, xsize, ysize,area_extent)\n",
    "    return area_def\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f660eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creation of area of interest:\n",
    "#corners = {\"min_lon\": 25 , \"max_lon\": 75, \"min_lat\": -30 , \"max_lat\": 0, \"lat_0\": 60, \"lon_0\":-15}\n",
    "corners = {\"min_lon\": -95 , \"max_lon\": 20, \"min_lat\": 3 , \"max_lat\": 50, \"lat_0\": 27, \"lon_0\":-57}\n",
    "proj_id = 'eqc'  # eqc\n",
    "datum = 'WGS84'\n",
    "area_interest = defineArea(corners, proj_id, datum)\n",
    "\n",
    "\n",
    "area_def_world = load_area('areas.yaml', 'worldeqc30km')# 'worldeqc30km70') # for plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09403382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Sat_frame(ds, area_interest, chan = 0, var=None, begin_t=None, end_t=None):\n",
    "    \n",
    "    grid_lons_interest, grid_lats_interest = area_interest.get_lonlats()\n",
    "\n",
    "    swathDef = SwathDefinition(lons=ds.lon.values, lats=ds.lat.values)\n",
    "    lon_scene, lat_scene = swathDef.get_lonlats()\n",
    "\n",
    "    if(chan>=0):\n",
    "        \n",
    "        reduced_lon_scene, reduced_lat_scene, reduced_data_scene = \\\n",
    "                           data_reduce.swath_from_lonlat_grid(\n",
    "            grid_lons_interest, grid_lats_interest,\n",
    "            lon_scene, lat_scene, ds[var][:,:,chan].values,\n",
    "            radius_of_influence=3000)\n",
    "    else:\n",
    "        reduced_lon_scene, reduced_lat_scene, reduced_data_scene = \\\n",
    "                           data_reduce.swath_from_lonlat_grid(\n",
    "            grid_lons_interest, grid_lats_interest,\n",
    "            lon_scene, lat_scene, ds[var][:,:].values,\n",
    "            radius_of_influence=3000)\n",
    "\n",
    "    return reduced_lon_scene, reduced_lat_scene, reduced_data_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3433e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TB_frame(ds, area_interest, channel, begin_t=None, end_t=None):\n",
    "    \n",
    "    grid_lons_interest, grid_lats_interest = area_interest.get_lonlats()\n",
    "\n",
    "    swathDef = SwathDefinition(lons=ds.lon.values, lats=ds.lat.values)\n",
    "    lon_scene, lat_scene = swathDef.get_lonlats()\n",
    "\n",
    "    reduced_lon_scene, reduced_lat_scene, reduced_data_scene = \\\n",
    "                           data_reduce.swath_from_lonlat_grid(\n",
    "        grid_lons_interest, grid_lats_interest,\n",
    "        lon_scene, lat_scene, ds.tb[:,channel,:].values,\n",
    "        radius_of_influence=3000)\n",
    "\n",
    "    return reduced_lon_scene, reduced_lat_scene, reduced_data_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946970de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicMapPlotScat(x,y,data,namefile, area, vmin=0, vmax=300):\n",
    "    # Make a Mercator map of the data using Cartopy\n",
    "    \n",
    "    crs = area.to_cartopy_crs()\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    #plt.figure(figsize=(8, 6))\n",
    "    ax = plt.axes(projection=crs)   \n",
    "    ax.add_feature(cartopy.feature.LAND, zorder=0, edgecolor='black')\n",
    "    ax.set_global()\n",
    "    ax.gridlines()        \n",
    "    ax.set_title(\"TB\")\n",
    "    \n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.1, \n",
    "                      color='black', alpha=0.5, linestyle='--', draw_labels=True)\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER    \n",
    "\n",
    "    # Plot the air temperature as colored circles and the wind speed as vectors.\n",
    "    im = ax.scatter(\n",
    "        x,\n",
    "        y,\n",
    "        c=data,\n",
    "        s=0.15,\n",
    "        cmap=\"viridis\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        #vmin=3, vmax=18         #180, 270\n",
    "        #vmin=130, vmax=270         #180, 270\n",
    "        vmin=vmin, vmax=vmax         #180, 270\n",
    "    )\n",
    "    fig.colorbar(im).set_label(\"Brightness temperature [K]\")\n",
    "    \n",
    "# Use an utility function to add tick labels and land and ocean features to the map.\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n",
    "    #plt.savefig(namefile+'.png', bbox_inches='tight', dpi=150) \n",
    "    \n",
    "def basicMapPlotScat1(x,y,data,namefile, area, vmin=0, vmax=300):\n",
    "    # Make a Mercator map of the data using Cartopy\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ortho = ccrs.PlateCarree() #ccrs.Orthographic(60,-15)\n",
    "    ax = plt.axes(projection=ortho)\n",
    "    \n",
    "    #crs = ccrs.RotatedPole(pole_longitude=177.5, pole_latitude=37.5)\n",
    "    geo = ccrs.Geodetic()\n",
    "    #crs = ccrs.Orthographic(60,-15)\n",
    "    \n",
    "    ax.add_feature(cartopy.feature.LAND, zorder=0, edgecolor='black')\n",
    "    \n",
    "    xy = ortho.transform_points(geo, x, y)\n",
    "\n",
    "    ax.set_global()\n",
    "    ax.gridlines()    \n",
    "    \n",
    "    #ax.set_title(\"TB\")\n",
    "    #ax.coastlines() \n",
    "    # Plot the air temperature as colored circles and the wind speed as vectors.\n",
    "    im = ax.scatter(\n",
    "        xy[:,0],\n",
    "        xy[:,1],\n",
    "        c=data,\n",
    "        s=0.05,\n",
    "        cmap=\"viridis\",\n",
    "        #transform=crs,\n",
    "        #vmin=3, vmax=18,  # 180, 270\n",
    "        #vmin=130, vmax=270         #180, 270\n",
    "        vmin=vmin, vmax=vmax         #180, 270       \n",
    "    )\n",
    "    #fig.colorbar(im).set_label(\"10m Wind Speed, HOAPS [m/s]\")\n",
    "    fig.colorbar(im).set_label(\"Temp. Bright [K]\")\n",
    "    \n",
    "# Use an utility function to add tick labels and land and ocean features to the map.\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    plt.savefig(namefile+'.png', bbox_inches='tight', dpi=300)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed6b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in range(4):\n",
    "    reduced_lon_scene, reduced_lat_scene, reduced_data_scene =\\\n",
    "    get_TB_frame(work_SAT_ds, area_def_world, channel)\n",
    "    \n",
    "    basicMapPlotScat1(reduced_lon_scene, reduced_lat_scene, reduced_data_scene,\n",
    "                 'scene_channel_'+str(channel), area_interest, vmin=130, vmax=270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2ce86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the resampled (Nearest neighb.) ECMWF data in the new 'grid' \n",
    "# (i.e. the satellite swath):\n",
    "\n",
    "reduced_lon_scene, reduced_lat_scene, reduced_data_scene =\\\n",
    "get_Sat_frame(work_SAT_ds, area_def_world, chan=3, \n",
    "              var = 'u10n_apriori_nn', begin_t=None, end_t=None)\n",
    "\n",
    "basicMapPlotScat1(reduced_lon_scene, reduced_lat_scene, reduced_data_scene,\n",
    "                 'resampled', area_interest, vmin=-25, vmax=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the resampled (Gaussian interp.) ECMWF data in the new 'grid' \n",
    "# (i.e. the satellite swath):\n",
    "\n",
    "#reduced_lon_scene, reduced_lat_scene, reduced_data_scene =\\\n",
    "#get_Sat_frame(work_SAT_ds, area_def_world, var='dataGauss', begin_t=None, end_t=None)\n",
    "\n",
    "reduced_lon_scene, reduced_lat_scene, reduced_data_scene =\\\n",
    "get_Sat_frame(work_SAT_ds, area_def_world, chan=3, \n",
    "              var = 'u10n_apriori_gauss', begin_t=None, end_t=None)\n",
    "\n",
    "basicMapPlotScat1(reduced_lon_scene, reduced_lat_scene, reduced_data_scene,\n",
    "                 'resampledGauss', area_interest, vmin=-25, vmax=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948cb16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_SAT_ds['differenceNN_GN'] = np.abs(work_SAT_ds['u10n_apriori_gauss'][:,:,0]-\n",
    "                                        work_SAT_ds['u10n_apriori_gauss'][:,:,3])\n",
    "\n",
    "reduced_lon_scene, reduced_lat_scene, reduced_data_scene =\\\n",
    "get_Sat_frame(work_SAT_ds, area_def_world, chan=-1, \n",
    "              var = 'differenceNN_GN', begin_t=None, end_t=None)\n",
    "\n",
    "basicMapPlotScat1(reduced_lon_scene, reduced_lat_scene, reduced_data_scene,\n",
    "                 'difference_NN_GN', area_interest, vmin=0, vmax=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#work_SAT_ds['u10n_apriori_gauss_interp'] \n",
    "\n",
    "reduced_lon_scene, reduced_lat_scene, reduced_data_scene =\\\n",
    "get_Sat_frame(work_SAT_ds, area_def_world, chan=-1, \n",
    "              var = 'u10n_apriori_gauss_interp', begin_t=None, end_t=None)\n",
    "\n",
    "basicMapPlotScat1(reduced_lon_scene, reduced_lat_scene, reduced_data_scene,\n",
    "                 'spaceTimeInterpolated', area_interest, vmin=-25, vmax=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c669807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot origin data (ECMWF on regular grid, to compare with the resampled one):\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "work_ECMWF_ds.u10n[:,:,0].where(\n",
    "    work_ECMWF_ds.lsm[:,:,0]==0).plot(ax=ax,\n",
    "    transform=ccrs.PlateCarree(), cmap=\"viridis\")\n",
    "ax.scatter(reduced_lon_scene, reduced_lat_scene,marker='.',color='red')\n",
    "plt.tight_layout()\n",
    "plt.savefig('allWind_and_swath.png', bbox_inches='tight', dpi=300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapPlotScatZoom(x,y,data,namefile, mini, maxi, orthoCenter=None, area=None):\n",
    "    # Make a Mercator map of the data using Cartopy\n",
    "      \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    if(area==None):\n",
    "        #ortho = ccrs.Orthographic(0,-15) # ccrs.Orthographic(60,-15)\n",
    "        ortho = ccrs.PlateCarree()\n",
    "        ax = plt.axes(projection=ortho)\n",
    "        \n",
    "        #crs = ccrs.RotatedPole(pole_longitude=177.5, pole_latitude=37.5)\n",
    "        geo = ccrs.PlateCarree() #ccrs.Geodetic()\n",
    "        #crs = ccrs.Orthographic(60,-15)\n",
    "    else:\n",
    "        crs = area.to_cartopy_crs()\n",
    "        #ortho = crs.Orthographic(0,-15) # crs.Orthographic(60,-15)\n",
    "        ortho = crs #crs.PlateCarree()\n",
    "        ax = plt.axes(projection=ortho)\n",
    "        \n",
    "        #crs = crs.RotatedPole(pole_longitude=177.5, pole_latitude=37.5)\n",
    "        geo = ccrs.PlateCarree() #ccrs.Geodetic()\n",
    "        #crs = crs.Orthographic(60,-15)\n",
    "        \n",
    "    \n",
    "    ax.add_feature(cartopy.feature.LAND, zorder=0, edgecolor='black',linewidth=0.1)\n",
    "    \n",
    "    xy = ortho.transform_points(geo, x, y)\n",
    "\n",
    "    ax.set_global()\n",
    "    #ax.gridlines()    \n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.07, \n",
    "                      color='black', alpha=0.5, linestyle='--', draw_labels=True)\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER  \n",
    "    \n",
    "    work_ECMWF_ds.u10n[:,:,0].where(\n",
    "    work_ECMWF_ds.lsm[:,:,0]==0).plot(ax=ax,\n",
    "    transform=ccrs.PlateCarree(), cmap=\"viridis\")\n",
    "    \n",
    "    # Plot the air temperature as colored circles and the wind speed as vectors.\n",
    "    im = ax.scatter(\n",
    "        xy[:,0],\n",
    "        xy[:,1],\n",
    "        #c=data,\n",
    "        #marker='.',\n",
    "        s=6, #0.15\n",
    "        edgecolors= 'none',\n",
    "        marker = matplotlib.markers.MarkerStyle(marker='o',fillstyle='full'),#\"o\",\n",
    "        color='red'\n",
    "        #cmap=\"viridis\",\n",
    "        )\n",
    "    #fig.colorbar(im).set_label(\"10m Wind Speed, RadEst [m/s]\")\n",
    "    \n",
    "# Use an utility function to add tick labels and land and ocean features to the map.\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    plt.savefig(namefile+'.jpg', bbox_inches='tight', dpi=900)  \n",
    "\n",
    "\n",
    "corners = {\"min_lon\": 55 , \"max_lon\": 57, \"min_lat\": -22 , \"max_lat\": -20, \"lat_0\": 0, \"lon_0\":0}\n",
    "proj_id = 'eqc'  # eqc\n",
    "datum = 'WGS84'\n",
    "area_interest = defineArea(corners, proj_id, datum)\n",
    "#grid_lons_zoom, grid_lats_zoom = area_interest.get_lonlats()\n",
    "\n",
    "\n",
    "zoom_lon_scene, zoom_lat_scene, zoom_data_scene =\\\n",
    "get_Sat_frame(work_SAT_ds, area_interest, chan=-1, \n",
    "              var = 'u10n_apriori_gauss_interp', begin_t=None, end_t=None)\n",
    "\n",
    "#basicMapPlotScat1(zoom_lon_scene, zoom_lat_scene, zoom_data_scene,\n",
    "#                 'spaceTimeInterpolated', area_interest, vmin=-25, vmax=25)\n",
    "\n",
    "mapPlotScatZoom(zoom_lon_scene, zoom_lat_scene, zoom_data_scene,\n",
    "                 'zoom3', -25,25,area=area_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fde46cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom_lon_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some histograms:\n",
    "\n",
    "#ds_tb_log = np.log10(ds_work.tb[:,0,:]) \n",
    "#ds_work.tb[:,0,:].plot.hist(bins=20,)\n",
    "#ds_tb_log.plot.hist(bins=30,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8da72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigHistogram(da, numbins=20):\n",
    "    # Computing histogram of all the values contained in dataarray da:\n",
    "    # We resort to this way of computing the histogram because\n",
    "    # the normal xarray.plot.hist produced strange plots:\n",
    "\n",
    "    datamin = np.nanmin(da.values)\n",
    "    datamax = np.nanmax(da.values)\n",
    "    #numbins = 20\n",
    "\n",
    "    delta = (datamax-datamin)/numbins\n",
    "    mybins =np.linspace(datamin+delta/2,\n",
    "                    datamax-delta/2,\n",
    "                    numbins) # Bins midpoint locations\n",
    "    # Cycle in time:\n",
    "    #hist, _ = np.histogram(da.isel(time=0).values.ravel(), bins = numbins,\n",
    "    #                       range=(np.nanmin(da.isel(time=0)),np.nanmax(da.isel(time=0))))\n",
    "    #for i in range(1, len(da[\"time\"])):\n",
    "    #    hist += np.histogram(da.isel(time=i).values.ravel(), bins = numbins,\n",
    "    #                        range=(np.nanmin(da.isel(time=i)),np.nanmax(da.isel(time=i))))[0]\n",
    "\n",
    "    hist, _ = np.histogram(da.isel(scene_across_track=0).values.ravel(), bins = numbins,\n",
    "                       range=(np.nanmin(da.isel(scene_across_track=0)),\n",
    "                              np.nanmax(da.isel(scene_across_track=0))))\n",
    "    for i in range(1, len(da[\"scene_across_track\"])):\n",
    "        hist += np.histogram(da.isel(scene_across_track=i).values.ravel(), bins = numbins,\n",
    "                        range=(np.nanmin(da.isel(scene_across_track=i)),\n",
    "                               np.nanmax(da.isel(scene_across_track=i))))[0]\n",
    "        print('Step '+str(i)+' of '+\n",
    "             str(len(da[\"scene_across_track\"]))+\n",
    "             ' done!')\n",
    "    \n",
    "    return hist, mybins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693faae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels: \n",
    "# 0 => 19 GHz, H\n",
    "# 1 => 19 GHz, V\n",
    "# 2 => 37 GHz, H\n",
    "# 3 => 37 GHz, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7665a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = SAT_ds.tb[:,3,:].dropna(\n",
    "    dim='time', how='all').chunk(\n",
    "    chunks={'time':45000})\n",
    "\n",
    "numbins = 20\n",
    "hist, bins = bigHistogram(da, numbins=numbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d751cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56dfc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram using seaborn:\n",
    "plt.figure()\n",
    "sns.histplot(x=bins, weights=hist, discrete=False, bins=numbins)\n",
    "plt.xlabel('Temperature Brightness [K] ')\n",
    "plt.grid(visible=True)\n",
    "plt.title('Distribution of Temp. Brightness in channel 37V')\n",
    "plt.savefig('hist_TB_channel37V.png',dpi =150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a6beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "da0 = SAT_ds.tb[:,0,:].dropna(\n",
    "    dim='time', how='all').chunk(\n",
    "    chunks={'time':45000})\n",
    "da1 = SAT_ds.tb[:,3,:].dropna(\n",
    "    dim='time', how='all').chunk(\n",
    "    chunks={'time':45000})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa76b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "da0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a9910",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(da0.stack(index=(\"time\",\"scene_across_track\")), \n",
    "           da1.stack(index=(\"time\",\"scene_across_track\")))\n",
    "plt.xlabel('Temperature Brightness [K], 19H')\n",
    "plt.ylabel('Temperature Brightness [K], 37V')\n",
    "plt.grid(visible=True)\n",
    "plt.title('Scatter plot 19H vs 37V')\n",
    "#plt.show()\n",
    "plt.savefig('scatter_19H_37V.png',dpi =150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50635f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tb = SAT_ds.tb[:,:,:].dropna(\n",
    "    dim='time', how='all')\n",
    "ds_tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab051fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = SAT_ds.tb[:,:,:].stack(\n",
    "    index=('time','scene_across_track'\n",
    "          )).transpose(\"index\", \"scene_channel\"\n",
    "                      ).dropna(how='all', dim = 'index'\n",
    "                   ).to_pandas().shape[0] #.to_csv('scores.csv')\n",
    "\n",
    "newIndex = np.arange(nrows)\n",
    "\n",
    "dataframe_TB = SAT_ds.tb[:,:,:].stack(\n",
    "    index=('time','scene_across_track'\n",
    "          )).transpose(\"index\", \"scene_channel\"\n",
    "                      ).dropna(how='all', dim = 'index'\n",
    "                              ).to_pandas().set_index(\n",
    "    keys=newIndex)\n",
    "dataframe_TB.index.name = 'example'\n",
    "dataframe_TB #.to_csv('eigenVal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682881e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe_TB.to_csv('dataframe_TB.csv')\n",
    "dataframe_TB = pd.read_csv('dataframe_TB.csv')\n",
    "del dataframe_TB['example']\n",
    "dataframe_TB.index.name = 'example'\n",
    "dataframe_TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(dataframe_TB, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01caaa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_outliers = train_test_split(X_test, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfad996",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outliers.iloc[0:100000,:] = X_outliers.iloc[0:100000,:] + 3\n",
    "X_outliers.iloc[100001:200000,:] = X_outliers.iloc[100001:200000,:] - 3\n",
    "X_outliers.iloc[200001:300000,:] = X_outliers.iloc[200001:300000,:] + 5\n",
    "X_outliers.iloc[300001:400000,:] = X_outliers.iloc[300001:400000,:] - 5\n",
    "X_outliers.iloc[400001:500000,:] = X_outliers.iloc[400001:500000,:] + 10\n",
    "X_outliers.iloc[500001:600000,:] = X_outliers.iloc[500001:600000,:] - 10\n",
    "X_outliers.iloc[600001:645857,:] = X_outliers.iloc[600001:645857,:] + 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564675c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "\n",
    "#clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1, verbose = 1)\n",
    "#clf.fit(X_train)\n",
    "#y_pred_train = clf.predict(X_train)\n",
    "#y_pred_test = clf.predict(X_test)\n",
    "#y_pred_outliers = clf.predict(X_outliers)\n",
    "#n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "#n_error_test = y_pred_test[y_pred_test == -1].size\n",
    "#n_error_outliers = y_pred_outliers[y_pred_outliers == 1].size\n",
    "\n",
    "nu = 0.05\n",
    "gamma = 2.0\n",
    "random_state = 42\n",
    "# Fit the One-Class SVM using a kernel approximation and SGD\n",
    "transform = Nystroem(gamma=gamma, random_state=random_state)\n",
    "clf_sgd = SGDOneClassSVM(nu=nu, shuffle=True, \n",
    "                         fit_intercept=True, random_state=random_state, \n",
    "                         tol=1e-4, verbose = 1)\n",
    "\n",
    "pipe_sgd = make_pipeline(transform, clf_sgd)\n",
    "pipe_sgd.fit(X_train)\n",
    "y_pred_train_sgd = pipe_sgd.predict(X_train)\n",
    "y_pred_test_sgd = pipe_sgd.predict(X_test)\n",
    "y_pred_outliers_sgd = pipe_sgd.predict(X_outliers)\n",
    "n_error_train_sgd = y_pred_train_sgd[y_pred_train_sgd == -1].size\n",
    "n_error_test_sgd = y_pred_test_sgd[y_pred_test_sgd == -1].size\n",
    "n_error_outliers_sgd = y_pred_outliers_sgd[y_pred_outliers_sgd == 1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6750e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(da):\n",
    "    \n",
    "    # Inputs:\n",
    "    # da, xarray datarray\n",
    "    \n",
    "    # Outputs:\n",
    "    # listMatrices, list of covariances to be shaped as a numpy 2D array.\n",
    "    \n",
    "    listMatrices = []\n",
    "    #listIndices = []\n",
    "    \n",
    "    for channel1 in da.scene_channel:\n",
    "        for channel2 in da.scene_channel:\n",
    "        \n",
    "            listMatrices.append(  # Compute the variance and append it to the list of variances.\n",
    "                xr.cov( da.sel(scene_channel=channel1).stack(\n",
    "                    index=('time','scene_across_track')).chunk(\n",
    "                    chunks={'index':1000000}), \n",
    "                   da.sel(scene_channel=channel2).stack(\n",
    "                    index=('time','scene_across_track')).chunk(\n",
    "                    chunks={'index':1000000}), \n",
    "                       dim='index').compute().values\n",
    "            ) \n",
    "            #print('Variable: '+str(channel1)+str(channel2)+', appended')          \n",
    "\n",
    "    print(\"Computed variances: \")\n",
    "    print(listMatrices)\n",
    "    #print(listIndices)\n",
    "    \n",
    "    \n",
    "    # Return the diagonal matrix of covariances and the names of the indices\n",
    "    return listMatrices #np.diag(out), listIndices  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9568d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With xarray option 1 (only diagonal terms):\n",
    "\n",
    "#ds_cov = xr.cov(ds_tb, ds_tb, dim = 'index')\n",
    "#ds_cov\n",
    "\n",
    "# With xarray option 2 (full matrix):\n",
    "covList = covariance(ds_tb)\n",
    "covList\n",
    "\n",
    "covMatrix = np.asarray(covList).reshape((4,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b07ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenVal, eigenVec = np.linalg.eig(covMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c31f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigVal_DataArray = xr.DataArray(data=np.diag(eigenVal), \n",
    "                                dims=['channel_latentSpace','channel_latentSpace_T'])\n",
    "eigVal_DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42287918",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_DataArray = xr.DataArray(data=covMatrix, \n",
    "                             dims=['scene_channel','scene_channel_T'])\n",
    "cov_DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenVec_DataArray = xr.DataArray(data=eigenVec, \n",
    "                                  dims=['scene_channel','scene_channel_reduced'])\n",
    "eigenVec_DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c09557",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_DataArray.to_pandas().to_csv('covariance.csv')\n",
    "eigenVec_DataArray.to_pandas().to_csv('eigenVec.csv')\n",
    "eigVal_DataArray.to_pandas().to_csv('eigenVal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab02dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ds_T = ds_tb.stack(\n",
    "#    index=('time','scene_across_track')).chunk(\n",
    "#    chunks={'index':1000000}).dot(w_DataArray)\n",
    "#ds_T\n",
    "\n",
    "ds_T = xr.dot(ds_tb.stack(\n",
    "    index=('time','scene_across_track')).chunk(\n",
    "    chunks={'index':1000000}), \n",
    "              eigenVec_DataArray)\n",
    "ds_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111426a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(ds_T[:,0], \n",
    "           ds_T[:,1])\n",
    "plt.xlabel('Scores_0 [Units]')\n",
    "plt.ylabel('Scores_3 [Units]')\n",
    "plt.grid(visible=True)\n",
    "plt.title('Scatter plot Scores_0 vs Scores_3')\n",
    "#plt.show()\n",
    "plt.savefig('scatter_Scores_0_Scores_3.png',dpi =150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf25531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(ds_T[:,0], \n",
    "           ds_T[:,1], ds_T[:,2])\n",
    "\n",
    "ax.set_xlabel('Scores_0 [Units]')\n",
    "ax.set_ylabel('Scores_1 [Units]')\n",
    "ax.set_zlabel('Scores_2 [Units]')\n",
    "\n",
    "#plt.grid(visible=True)\n",
    "#plt.title('Scatter plot Scores_0_1_2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = ds_T.dropna(how='all', dim = 'index').to_pandas().shape[0] #.to_csv('scores.csv')\n",
    "newIndex = np.arange(nrows)\n",
    "\n",
    "dataframe_scores = ds_T.dropna(how='all', dim = 'index'\n",
    "                              ).to_pandas().set_index(\n",
    "    keys=newIndex)\n",
    "dataframe_scores.index.name = 'example'\n",
    "dataframe_scores #.to_csv('eigenVal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195a3288",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_scores.to_csv('scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24eb40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = pd.read_csv('scores.csv')\n",
    "#scores\n",
    "dataframe_scores.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e1585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram using seaborn:\n",
    "plt.figure()\n",
    "sns.histplot(data = dataframe_scores.iloc[:,0], bins=20)\n",
    "plt.xlabel('Score_0')\n",
    "plt.grid(visible=True)\n",
    "plt.title('Distribution of Score 0')\n",
    "plt.savefig('hist_Score0.png',dpi =150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf48eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.jointplot(dataframe_scores.iloc[:,0:2], x = 0, y = 1)\n",
    "plt.xlabel('Score_0')\n",
    "plt.ylabel('Score_1')\n",
    "plt.grid(visible=True)\n",
    "plt.title('Distribution of Score 0 and 1')\n",
    "plt.savefig('JoinPlot_Score0_1.png',dpi =150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce03d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.displot(dataframe_scores.iloc[:,0:2], x = 0, y = 1)\n",
    "plt.xlabel('Score_0')\n",
    "plt.ylabel('Score_1')\n",
    "plt.grid(visible=True)\n",
    "plt.title('Distribution of Score 0 and 1')\n",
    "plt.savefig('hist2D_Score0_1.png',dpi =150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv('scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcadf311",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2acb18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa08b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
