{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c342a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import pyproj\n",
    "import pyresample\n",
    "from pyresample import create_area_def, load_area, data_reduce, utils, AreaDefinition\n",
    "from pyresample.geometry import SwathDefinition\n",
    "from pyresample.kd_tree import resample_nearest \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e889a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/mario/Documents/Coursera\\\n",
    "/Unsupervised/week1/Labs/Lab2/Files/home/jovyan/work')\n",
    "from utils import *\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebbc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MALLOC_TRIM_THRESHOLD_\"] = \"0\"#\"65536\"\n",
    "\n",
    "from dask.distributed import Client, progress, LocalCluster\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde466cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = '/home/mario/Data/CMSAF/ssims/F16/'\n",
    "fileID = 'BTRin20140909000000324SSF1601GL.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c88aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = xr.open_dataset(dataDir+fileID)\n",
    "ds = xr.open_mfdataset(dataDir+'*.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b88e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_list = ['scene_env1', 'scene_env2']\n",
    "scene_BT = []\n",
    "\n",
    "for scene in scenes_list:        \n",
    "    scene_BT.append(xr.open_mfdataset(\n",
    "        dataDir+'*.nc', combine = 'nested', \n",
    "        concat_dim='time', group = scene)) \n",
    "\n",
    "#for scene in scenes_list:\n",
    "    #scene_BT.append(xr.open_dataset(dataDir+fileID, group = scene))\n",
    "    #scene_BT.append(xr.open_mfdataset(dataDir+'*.nc', group = scene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_BT[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_BT = xr.concat(scene_BT, dim = 'scene_channel').drop_vars([\n",
    "])\n",
    "\n",
    "ds_BT['lat'] = ds_BT.lat[0,:,:]\n",
    "ds_BT['lon'] = ds_BT.lon[0,:,:]\n",
    "ds_BT['eia'] = ds_BT.eia[0,:,:]\n",
    "ds_BT['sft'] = ds_BT.sft[0,:,:]\n",
    "ds_BT['qc_fov'] = ds_BT.qc_fov[0,:,:]\n",
    "ds_BT['laz'] = ds_BT.laz[0,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3dee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_aux = ds_BT.assign_coords(time=ds.time).sel(\n",
    "    scene_channel=[11,12,14,15]).where(ds_BT.sft==0)\n",
    "\n",
    "ds_aux['central_freq'] = ds['central_freq'][0,0,ds_aux['scene_channel']]\n",
    "\n",
    "ds_work = ds_aux #.drop_dims(drop_dims = ['date','channel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc773a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineArea(corners, proj_id, datum):\n",
    "    #corners=parseMeta(data_name)\n",
    "\n",
    "    lat_0 = '{lat_0:5.2f}'.format_map(corners)\n",
    "    lon_0= '{lon_0:5.2f}'.format_map(corners)\n",
    "    lon_bbox = [corners['min_lon'],corners['max_lon']]\n",
    "    lat_bbox = [corners['min_lat'],corners['max_lat']]\n",
    "#    area_dict = dict(datum=datum,lat_0=lat_0,lon_0=lon_0,\n",
    "#                proj=proj_id,units='m')\n",
    "\n",
    "    area_dict = dict(datum=datum,lat_0=-15,lon_0=60,\n",
    "                proj=proj_id,units='m',a=6370997.0,)\n",
    "\n",
    "    prj=pyproj.Proj(area_dict)\n",
    "    x, y = prj(lon_bbox, lat_bbox)\n",
    "    xsize=200\n",
    "    ysize=200\n",
    "    area_id = 'granule'\n",
    "    area_name = 'modis swath 5min granule'\n",
    "    area_extent = (x[0], y[0], x[1], y[1])\n",
    "    print(area_extent)\n",
    "    area_def = AreaDefinition(area_id, area_name, proj_id, \n",
    "                                   area_dict, xsize, ysize,area_extent)\n",
    "    return area_def\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f660eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creation of area of interest:\n",
    "#corners = {\"min_lon\": 25 , \"max_lon\": 75, \"min_lat\": -30 , \"max_lat\": 0, \"lat_0\": 60, \"lon_0\":-15}\n",
    "corners = {\"min_lon\": -95 , \"max_lon\": 20, \"min_lat\": 3 , \"max_lat\": 50, \"lat_0\": 27, \"lon_0\":-57}\n",
    "proj_id = 'eqc'  # eqc\n",
    "datum = 'WGS84'\n",
    "area_interest = defineArea(corners, proj_id, datum)\n",
    "\n",
    "\n",
    "area_def_world = load_area('areas.yaml', 'worldeqc30km')# 'worldeqc30km70') # for plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09403382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3433e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TB_frame(ds, area_interest, channel, begin_t=None, end_t=None):\n",
    "    \n",
    "    grid_lons_interest, grid_lats_interest = area_interest.get_lonlats()\n",
    "\n",
    "    swathDef = SwathDefinition(lons=ds.lon.values, lats=ds.lat.values)\n",
    "    lon_scene, lat_scene = swathDef.get_lonlats()\n",
    "\n",
    "    reduced_lon_scene, reduced_lat_scene, reduced_data_scene = \\\n",
    "                           data_reduce.swath_from_lonlat_grid(\n",
    "        grid_lons_interest, grid_lats_interest,\n",
    "        lon_scene, lat_scene, ds.tb[:,channel,:].values,\n",
    "        radius_of_influence=3000)\n",
    "\n",
    "    return reduced_lon_scene, reduced_lat_scene, reduced_data_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946970de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicMapPlotScat(x,y,data,namefile, area):\n",
    "    # Make a Mercator map of the data using Cartopy\n",
    "    \n",
    "    crs = area.to_cartopy_crs()\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    #plt.figure(figsize=(8, 6))\n",
    "    ax = plt.axes(projection=crs)   \n",
    "    ax.add_feature(cartopy.feature.LAND, zorder=0, edgecolor='black')\n",
    "    ax.set_global()\n",
    "    ax.gridlines()        \n",
    "    ax.set_title(\"TB\")\n",
    "    \n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.1, \n",
    "                      color='black', alpha=0.5, linestyle='--', draw_labels=True)\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER    \n",
    "\n",
    "    # Plot the air temperature as colored circles and the wind speed as vectors.\n",
    "    im = ax.scatter(\n",
    "        x,\n",
    "        y,\n",
    "        c=data,\n",
    "        s=0.15,\n",
    "        cmap=\"viridis\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        #vmin=3, vmax=18         #180, 270\n",
    "        vmin=130, vmax=270         #180, 270\n",
    "    )\n",
    "    fig.colorbar(im).set_label(\"Brightness temperature [K]\")\n",
    "    \n",
    "# Use an utility function to add tick labels and land and ocean features to the map.\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n",
    "    #plt.savefig(namefile+'.png', bbox_inches='tight', dpi=150) \n",
    "    \n",
    "def basicMapPlotScat1(x,y,data,namefile, area):\n",
    "    # Make a Mercator map of the data using Cartopy\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ortho = ccrs.Orthographic(60,-15)\n",
    "    ax = plt.axes(projection=ortho)\n",
    "    \n",
    "    crs = ccrs.RotatedPole(pole_longitude=177.5, pole_latitude=37.5)\n",
    "    geo = ccrs.Geodetic()\n",
    "    #crs = ccrs.Orthographic(60,-15)\n",
    "    \n",
    "    ax.add_feature(cartopy.feature.LAND, zorder=0, edgecolor='black')\n",
    "    \n",
    "    xy = ortho.transform_points(geo, x, y)\n",
    "\n",
    "    ax.set_global()\n",
    "    ax.gridlines()    \n",
    "    \n",
    "    #ax.set_title(\"TB\")\n",
    "    #ax.coastlines() \n",
    "    # Plot the air temperature as colored circles and the wind speed as vectors.\n",
    "    im = ax.scatter(\n",
    "        xy[:,0],\n",
    "        xy[:,1],\n",
    "        c=data,\n",
    "        s=0.15,\n",
    "        cmap=\"viridis\",\n",
    "        #transform=crs,\n",
    "        #vmin=3, vmax=18,  # 180, 270\n",
    "        vmin=130, vmax=270,  # 180, 270        \n",
    "    )\n",
    "    #fig.colorbar(im).set_label(\"10m Wind Speed, HOAPS [m/s]\")\n",
    "    fig.colorbar(im).set_label(\"Temp. Bright [K]\")\n",
    "    \n",
    "# Use an utility function to add tick labels and land and ocean features to the map.\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    plt.savefig(namefile+'.png', bbox_inches='tight', dpi=300)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed6b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in range(4):\n",
    "    reduced_lon_scene, reduced_lat_scene, reduced_data_scene =\\\n",
    "    get_TB_frame(ds_work, area_def_world, channel)\n",
    "    \n",
    "    basicMapPlotScat1(reduced_lon_scene, reduced_lat_scene, reduced_data_scene,\n",
    "                 'scene_channel_'+str(channel), area_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some histograms:\n",
    "\n",
    "#ds_tb_log = np.log10(ds_work.tb[:,0,:]) \n",
    "#ds_work.tb[:,0,:].plot.hist(bins=20,)\n",
    "#ds_tb_log.plot.hist(bins=30,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8da72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigHistogram(da, numbins=20):\n",
    "    # Computing histogram of all the values contained in dataarray da:\n",
    "    # We resort to this way of computing the histogram because\n",
    "    # the normal xarray.plot.hist produced strange plots:\n",
    "\n",
    "    datamin = np.nanmin(da.values)\n",
    "    datamax = np.nanmax(da.values)\n",
    "    #numbins = 20\n",
    "\n",
    "    delta = (datamax-datamin)/numbins\n",
    "    mybins =np.linspace(datamin+delta/2,\n",
    "                    datamax-delta/2,\n",
    "                    numbins) # Bins midpoint locations\n",
    "    # Cycle in time:\n",
    "    #hist, _ = np.histogram(da.isel(time=0).values.ravel(), bins = numbins,\n",
    "    #                       range=(np.nanmin(da.isel(time=0)),np.nanmax(da.isel(time=0))))\n",
    "    #for i in range(1, len(da[\"time\"])):\n",
    "    #    hist += np.histogram(da.isel(time=i).values.ravel(), bins = numbins,\n",
    "    #                        range=(np.nanmin(da.isel(time=i)),np.nanmax(da.isel(time=i))))[0]\n",
    "\n",
    "    hist, _ = np.histogram(da.isel(scene_across_track=0).values.ravel(), bins = numbins,\n",
    "                       range=(np.nanmin(da.isel(scene_across_track=0)),\n",
    "                              np.nanmax(da.isel(scene_across_track=0))))\n",
    "    for i in range(1, len(da[\"scene_across_track\"])):\n",
    "        hist += np.histogram(da.isel(scene_across_track=i).values.ravel(), bins = numbins,\n",
    "                        range=(np.nanmin(da.isel(scene_across_track=i)),\n",
    "                               np.nanmax(da.isel(scene_across_track=i))))[0]\n",
    "        print('Step '+str(i)+' of '+\n",
    "             str(len(da[\"scene_across_track\"]))+\n",
    "             ' done!')\n",
    "    \n",
    "    return hist, mybins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693faae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels: \n",
    "# 0 => 19 GHz, H\n",
    "# 1 => 19 GHz, V\n",
    "# 2 => 37 GHz, H\n",
    "# 3 => 37 GHz, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7665a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds_work.tb[:,3,:].dropna(\n",
    "    dim='time', how='all').chunk(\n",
    "    chunks={'time':45000})\n",
    "\n",
    "numbins = 20\n",
    "hist, bins = bigHistogram(da, numbins=numbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d751cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56dfc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram using seaborn:\n",
    "plt.figure()\n",
    "sns.histplot(x=bins, weights=hist, discrete=False, bins=numbins)\n",
    "plt.xlabel('Temperature Brightness [K] ')\n",
    "plt.grid(visible=True)\n",
    "plt.title('Distribution of Temp. Brightness in channel 37V')\n",
    "plt.savefig('hist_TB_channel37V.png',dpi =150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a6beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "da0 = ds_work.tb[:,0,:].dropna(\n",
    "    dim='time', how='all').chunk(\n",
    "    chunks={'time':45000})\n",
    "da1 = ds_work.tb[:,3,:].dropna(\n",
    "    dim='time', how='all').chunk(\n",
    "    chunks={'time':45000})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa76b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "da0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a9910",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(da0.stack(index=(\"time\",\"scene_across_track\")), \n",
    "           da1.stack(index=(\"time\",\"scene_across_track\")))\n",
    "plt.xlabel('Temperature Brightness [K], 19H')\n",
    "plt.ylabel('Temperature Brightness [K], 37V')\n",
    "plt.grid(visible=True)\n",
    "plt.title('Scatter plot 19H vs 37V')\n",
    "#plt.show()\n",
    "plt.savefig('scatter_19H_37V.png',dpi =150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50635f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tb = ds_work.tb[:,:,:].dropna(\n",
    "    dim='time', how='all')\n",
    "ds_tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab051fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = ds_work.tb[:,:,:].stack(\n",
    "    index=('time','scene_across_track'\n",
    "          )).transpose(\"index\", \"scene_channel\"\n",
    "                      ).dropna(how='all', dim = 'index'\n",
    "                   ).to_pandas().shape[0] #.to_csv('scores.csv')\n",
    "\n",
    "newIndex = np.arange(nrows)\n",
    "\n",
    "dataframe_TB = ds_work.tb[:,:,:].stack(\n",
    "    index=('time','scene_across_track'\n",
    "          )).transpose(\"index\", \"scene_channel\"\n",
    "                      ).dropna(how='all', dim = 'index'\n",
    "                              ).to_pandas().set_index(\n",
    "    keys=newIndex)\n",
    "dataframe_TB.index.name = 'example'\n",
    "dataframe_TB #.to_csv('eigenVal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682881e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe_TB.to_csv('dataframe_TB.csv')\n",
    "dataframe_TB = pd.read_csv('dataframe_TB.csv')\n",
    "del dataframe_TB['example']\n",
    "dataframe_TB.index.name = 'example'\n",
    "dataframe_TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(dataframe_TB, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01caaa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_outliers = train_test_split(X_test, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfad996",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outliers.iloc[0:100000,:] = X_outliers.iloc[0:100000,:] + 3\n",
    "X_outliers.iloc[100001:200000,:] = X_outliers.iloc[100001:200000,:] - 3\n",
    "X_outliers.iloc[200001:300000,:] = X_outliers.iloc[200001:300000,:] + 5\n",
    "X_outliers.iloc[300001:400000,:] = X_outliers.iloc[300001:400000,:] - 5\n",
    "X_outliers.iloc[400001:500000,:] = X_outliers.iloc[400001:500000,:] + 10\n",
    "X_outliers.iloc[500001:600000,:] = X_outliers.iloc[500001:600000,:] - 10\n",
    "X_outliers.iloc[600001:645857,:] = X_outliers.iloc[600001:645857,:] + 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564675c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "\n",
    "#clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1, verbose = 1)\n",
    "#clf.fit(X_train)\n",
    "#y_pred_train = clf.predict(X_train)\n",
    "#y_pred_test = clf.predict(X_test)\n",
    "#y_pred_outliers = clf.predict(X_outliers)\n",
    "#n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "#n_error_test = y_pred_test[y_pred_test == -1].size\n",
    "#n_error_outliers = y_pred_outliers[y_pred_outliers == 1].size\n",
    "\n",
    "nu = 0.05\n",
    "gamma = 2.0\n",
    "random_state = 42\n",
    "# Fit the One-Class SVM using a kernel approximation and SGD\n",
    "transform = Nystroem(gamma=gamma, random_state=random_state)\n",
    "clf_sgd = SGDOneClassSVM(nu=nu, shuffle=True, \n",
    "                         fit_intercept=True, random_state=random_state, \n",
    "                         tol=1e-4, verbose = 1)\n",
    "\n",
    "pipe_sgd = make_pipeline(transform, clf_sgd)\n",
    "pipe_sgd.fit(X_train)\n",
    "y_pred_train_sgd = pipe_sgd.predict(X_train)\n",
    "y_pred_test_sgd = pipe_sgd.predict(X_test)\n",
    "y_pred_outliers_sgd = pipe_sgd.predict(X_outliers)\n",
    "n_error_train_sgd = y_pred_train_sgd[y_pred_train_sgd == -1].size\n",
    "n_error_test_sgd = y_pred_test_sgd[y_pred_test_sgd == -1].size\n",
    "n_error_outliers_sgd = y_pred_outliers_sgd[y_pred_outliers_sgd == 1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6750e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(da):\n",
    "    \n",
    "    # Inputs:\n",
    "    # da, xarray datarray\n",
    "    \n",
    "    # Outputs:\n",
    "    # listMatrices, list of covariances to be shaped as a numpy 2D array.\n",
    "    \n",
    "    listMatrices = []\n",
    "    #listIndices = []\n",
    "    \n",
    "    for channel1 in da.scene_channel:\n",
    "        for channel2 in da.scene_channel:\n",
    "        \n",
    "            listMatrices.append(  # Compute the variance and append it to the list of variances.\n",
    "                xr.cov( da.sel(scene_channel=channel1).stack(\n",
    "                    index=('time','scene_across_track')).chunk(\n",
    "                    chunks={'index':1000000}), \n",
    "                   da.sel(scene_channel=channel2).stack(\n",
    "                    index=('time','scene_across_track')).chunk(\n",
    "                    chunks={'index':1000000}), \n",
    "                       dim='index').compute().values\n",
    "            ) \n",
    "            #print('Variable: '+str(channel1)+str(channel2)+', appended')          \n",
    "\n",
    "    print(\"Computed variances: \")\n",
    "    print(listMatrices)\n",
    "    #print(listIndices)\n",
    "    \n",
    "    \n",
    "    # Return the diagonal matrix of covariances and the names of the indices\n",
    "    return listMatrices #np.diag(out), listIndices  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9568d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With xarray option 1 (only diagonal terms):\n",
    "\n",
    "#ds_cov = xr.cov(ds_tb, ds_tb, dim = 'index')\n",
    "#ds_cov\n",
    "\n",
    "# With xarray option 2 (full matrix):\n",
    "covList = covariance(ds_tb)\n",
    "covList\n",
    "\n",
    "covMatrix = np.asarray(covList).reshape((4,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b07ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenVal, eigenVec = np.linalg.eig(covMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c31f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigVal_DataArray = xr.DataArray(data=np.diag(eigenVal), \n",
    "                                dims=['channel_latentSpace','channel_latentSpace_T'])\n",
    "eigVal_DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42287918",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_DataArray = xr.DataArray(data=covMatrix, \n",
    "                             dims=['scene_channel','scene_channel_T'])\n",
    "cov_DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenVec_DataArray = xr.DataArray(data=eigenVec, \n",
    "                                  dims=['scene_channel','scene_channel_reduced'])\n",
    "eigenVec_DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c09557",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_DataArray.to_pandas().to_csv('covariance.csv')\n",
    "eigenVec_DataArray.to_pandas().to_csv('eigenVec.csv')\n",
    "eigVal_DataArray.to_pandas().to_csv('eigenVal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab02dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ds_T = ds_tb.stack(\n",
    "#    index=('time','scene_across_track')).chunk(\n",
    "#    chunks={'index':1000000}).dot(w_DataArray)\n",
    "#ds_T\n",
    "\n",
    "ds_T = xr.dot(ds_tb.stack(\n",
    "    index=('time','scene_across_track')).chunk(\n",
    "    chunks={'index':1000000}), \n",
    "              eigenVec_DataArray)\n",
    "ds_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111426a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(ds_T[:,0], \n",
    "           ds_T[:,1])\n",
    "plt.xlabel('Scores_0 [Units]')\n",
    "plt.ylabel('Scores_3 [Units]')\n",
    "plt.grid(visible=True)\n",
    "plt.title('Scatter plot Scores_0 vs Scores_3')\n",
    "#plt.show()\n",
    "plt.savefig('scatter_Scores_0_Scores_3.png',dpi =150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf25531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(ds_T[:,0], \n",
    "           ds_T[:,1], ds_T[:,2])\n",
    "\n",
    "ax.set_xlabel('Scores_0 [Units]')\n",
    "ax.set_ylabel('Scores_1 [Units]')\n",
    "ax.set_zlabel('Scores_2 [Units]')\n",
    "\n",
    "#plt.grid(visible=True)\n",
    "#plt.title('Scatter plot Scores_0_1_2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = ds_T.dropna(how='all', dim = 'index').to_pandas().shape[0] #.to_csv('scores.csv')\n",
    "newIndex = np.arange(nrows)\n",
    "\n",
    "dataframe_scores = ds_T.dropna(how='all', dim = 'index'\n",
    "                              ).to_pandas().set_index(\n",
    "    keys=newIndex)\n",
    "dataframe_scores.index.name = 'example'\n",
    "dataframe_scores #.to_csv('eigenVal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195a3288",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_scores.to_csv('scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24eb40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = pd.read_csv('scores.csv')\n",
    "#scores\n",
    "dataframe_scores.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e1585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram using seaborn:\n",
    "plt.figure()\n",
    "sns.histplot(data = dataframe_scores.iloc[:,0], bins=20)\n",
    "plt.xlabel('Score_0')\n",
    "plt.grid(visible=True)\n",
    "plt.title('Distribution of Score 0')\n",
    "plt.savefig('hist_Score0.png',dpi =150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf48eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.jointplot(dataframe_scores.iloc[:,0:2], x = 0, y = 1)\n",
    "plt.xlabel('Score_0')\n",
    "plt.ylabel('Score_1')\n",
    "plt.grid(visible=True)\n",
    "plt.title('Distribution of Score 0 and 1')\n",
    "plt.savefig('JoinPlot_Score0_1.png',dpi =150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce03d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.displot(dataframe_scores.iloc[:,0:2], x = 0, y = 1)\n",
    "plt.xlabel('Score_0')\n",
    "plt.ylabel('Score_1')\n",
    "plt.grid(visible=True)\n",
    "plt.title('Distribution of Score 0 and 1')\n",
    "plt.savefig('hist2D_Score0_1.png',dpi =150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv('scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcadf311",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2acb18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
